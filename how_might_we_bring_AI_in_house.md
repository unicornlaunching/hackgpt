# How Might We Bring AI In-House?

TL;DR Protecting your data will be a challenge you'll fail to conquer in the end....but that doesn't mean you can't be compliant :P

## It's all fun and games until you realize Cambridge Analytica was selling your data THE WHOLE MOVIE.

Is security and privacy a pipe dream given that we're vectorizing our trade secrets?

"VECTORIZING OUR TRADE SECRETS?! SPEAK ENGLISH!"

OK OK - let's take a step back.

---

## Let's understand Large Language Models (LLMs) at a High Level

Large Language Models are language comprehension experts. In other words, they're good at words.

If you knew an expert in language, what would you have them do? Well, if you're Gen Z, you'd ask the language expert to write your essay on Lord of the Flies. If you're Gen X, you'll ask it to write a statement of work. You get the idea.

Notice that in both of those scenarios - writing an essay on Lord of the Flies or writing an SOW - garbage in, garbage out. If the language expert doesn't know Lord of the Flies, it won't be able to write an essay about it. Worse, it may just make one up like an unprepared Gen Z would.

So, garbage in, garbage out. Your large language model is only as good as the data you've given it BEFORE you start asking it questions.

## Mutually-Assured Computation

Many people talk about AI as if it could be regulated; hilarious. We can't even regulate guns. You think you can regulate a systems administrator? Good luck.

Even deeper, you couldn't stop AI no more than you could stop nuclear proliferation. Society advances by the number of operations it can perform without thinking (Whitehead). Given that AI allows fitness at a state-level, each state will have to adopt an AI strategy or remain a vassal state of RomAIns.

## So where is all this going? Get to the point already JEEZ.

### Q: How many of your trade secrets are being leaked onto the internet just because your employees are trying to hit a deadline faster and analyzing all of your crown jewels with AI?

A: The answer is unknowable; but you get the point.

If AI is the best assistant on the planet, it stands to reason that humans are going to tell it all of their problems. And for the AI to solve their problems, the humans are going to hand over their data.

### The approach to counterract the sharing of trade secrets with AI will be to bring AI in-house.

Which begs the question...how might we bring AI in-house?

In order to bring AI in-house, you're going to need to bring a few things in-house:
- compute
- network
- storage
- large language models

Long story short, what this means is that we're about to sea a wave of companies repatriating or brining a certain amount of compute, network, storage, and large language models back in-house to make sure that Cambridge Analytica 2.0 doesn't hit them in five years.

## Bringing AI in-house...will this prevent data theft? Ransomware? Nope.

The largest companies on the planet are crawling each other's sites, knowing that they can foot the bill and that the data is worth the cost (think Ford Pinto math).

Data theft is going to happen because of the unreasonable effectiveness of data. Algorithms, as Dr. Herb Roitblat said, aren't enough. The performance of AI systems are based on the volume and quality of data; garbage in, garbage out.

As if you're gonna stop Cambridge Analytica, whatever they call it next.

Don't quote laws to men who have swords.
- Magnus Pompey

## What can you do in the meantime?
Talk to your Chief Information Security Officer, and get your Access Control List. That ACL or Access Control List will tell you who has access to what.

Your ACL will help you determine:
- What should be kept in-house
- What doesn't need to be kept in-house

For more information about how to tackle this challenge - and it will be a challenge, come to the Hackathon.

Protecting your data will be a challenge you'll fail to conquer in the end....but that doesn't mean you can't be compliant :P
